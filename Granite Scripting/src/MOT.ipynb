{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AI Generation of the MOT Model YAML Files \n",
    "*With IBM Granite*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## In this notebook\n",
    "This notebook contains instructions for performing YAML Model generation via custom Granite flow with Ollama.\n",
    "This notebook is heavily inspired by the official IBM Granite workshop, for the hardware setup please refer to the [workshop](https://ibm.github.io/granite-workshop/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting up the environment\n",
    "\n",
    "Ensure you are running python 3.10, 3.11, or 3.12 in a freshly-created virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 10) and sys.version_info < (3, 13), \"Use Python 3.10, 3.11, or 3.12 to run this notebook.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Granite utils provides some helpful functions for recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ibm-granite-community/utils\n",
      "  Cloning https://github.com/ibm-granite-community/utils to /tmp/pip-req-build-kn3_156t\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite-community/utils /tmp/pip-req-build-kn3_156t\n",
      "  Resolved https://github.com/ibm-granite-community/utils to commit da3c800822615230c65b4d4cdee3bc7e48cbfa60\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: langchain_community in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain_huggingface in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: langchain_ollama in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: langchain_milvus in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: replicate in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (1.0.7)\n",
      "Requirement already satisfied: wget in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (3.2)\n",
      "Requirement already satisfied: requests in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from ibm-granite-community-utils==0.1.dev81) (1.1.0)\n",
      "Requirement already satisfied: langchain_core in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from ibm-granite-community-utils==0.1.dev81) (0.3.64)\n",
      "Requirement already satisfied: typing_extensions in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from ibm-granite-community-utils==0.1.dev81) (4.14.0)\n",
      "Requirement already satisfied: filelock in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_community) (3.12.9)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_community) (0.3.45)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_core->ibm-granite-community-utils==0.1.dev81) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain_core->ibm-granite-community-utils==0.1.dev81) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_huggingface) (4.1.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_ollama) (0.5.1)\n",
      "Requirement already satisfied: pymilvus<3.0,>=2.5.7 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from langchain_milvus) (2.5.10)\n",
      "Requirement already satisfied: setuptools>69 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pymilvus<3.0,>=2.5.7->langchain_milvus) (80.9.0)\n",
      "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pymilvus<3.0,>=2.5.7->langchain_milvus) (1.67.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pymilvus<3.0,>=2.5.7->langchain_milvus) (6.31.1)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pymilvus<3.0,>=2.5.7->langchain_milvus) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pymilvus<3.0,>=2.5.7->langchain_milvus) (2.3.0)\n",
      "Requirement already satisfied: milvus-lite>=2.4.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pymilvus<3.0,>=2.5.7->langchain_milvus) (2.4.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus<3.0,>=2.5.7->langchain_milvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus<3.0,>=2.5.7->langchain_milvus) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus<3.0,>=2.5.7->langchain_milvus) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus<3.0,>=2.5.7->langchain_milvus) (1.17.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.7.0)\n",
      "Requirement already satisfied: scipy in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.2.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/hice1/stae6/granite_env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.6.0)\n",
      "Building wheels for collected packages: ibm-granite-community-utils\n",
      "  Building wheel for ibm-granite-community-utils (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-granite-community-utils: filename=ibm_granite_community_utils-0.1.dev81-py3-none-any.whl size=12904 sha256=97cebadc8a0e4028d76e009719ba55609949fa18adbb03d16a4f6afe0a710103\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l1ohflyg/wheels/e2/74/0e/e7dc80cad1c61a0c57be9aff96c6c6bbb058052bc5b9cac0ff\n",
      "Successfully built ibm-granite-community-utils\n",
      "Installing collected packages: ibm-granite-community-utils\n",
      "  Attempting uninstall: ibm-granite-community-utils\n",
      "    Found existing installation: ibm-granite-community-utils 0.1.dev74\n",
      "    Uninstalling ibm-granite-community-utils-0.1.dev74:\n",
      "      Successfully uninstalled ibm-granite-community-utils-0.1.dev74\n",
      "Successfully installed ibm-granite-community-utils-0.1.dev81\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/ibm-granite-community/utils \\\n",
    "    transformers \\\n",
    "    langchain_community \\\n",
    "    langchain_huggingface \\\n",
    "    langchain_ollama \\\n",
    "    langchain_milvus \\\n",
    "    replicate \\\n",
    "    wget \\\n",
    "    requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving the Granite AI model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook requires IBM Granite models to be served by an AI model runtime so that the models can be invoked or called. This notebook can use a locally accessible [Ollama](https://github.com/ollama/ollama) server to serve the models, or the [Replicate](https://replicate.com) cloud service.\n",
    "\n",
    "During the pre-work, you may have either started a local Ollama server on your computer, or setup Replicate access and obtained an [API token](https://replicate.com/account/api-tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting System Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your Embeddings Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the model to use for generating embedding vectors from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "embeddings_model_path = \"ibm-granite/granite-embedding-30m-english\"\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=embeddings_model_path,\n",
    ")\n",
    "embeddings_tokenizer = AutoTokenizer.from_pretrained(embeddings_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your Vector Database\n",
    "\n",
    "Specify the database to use for storing and retrieving embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector database will be saved to /tmp/milvus_jo5azdsq.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/stae6/granite_env/lib/python3.12/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n",
      "2025-07-27 16:31:29,212 [DEBUG][_create_connection]: Created new connection using: 50ee2b6865a24602bc6bf11a4512e6b3 (async_milvus_client.py:599)\n"
     ]
    }
   ],
   "source": [
    "from langchain_milvus import Milvus\n",
    "import tempfile\n",
    "\n",
    "db_file = tempfile.NamedTemporaryFile(prefix=\"milvus_\", suffix=\".db\", delete=False).name\n",
    "print(f\"The vector database will be saved to {db_file}\")\n",
    "\n",
    "vector_db = Milvus(\n",
    "    embedding_function=embeddings_model,\n",
    "    connection_args={\"uri\": db_file},\n",
    "    auto_id=True,\n",
    "    index_params={\"index_type\": \"AUTOINDEX\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Select your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a Granite model to use. Here we use a Langchain client to connect to the model. If there is a locally accessible Ollama server, we use an Ollama client to access the model. Otherwise, we use a Replicate client to access the model.\n",
    "\n",
    "To use Replicate, please refer to [workshop](https://ibm.github.io/granite-workshop/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model_path = \"ibm-granite/granite-3.3-8b-instruct\"\n",
    "model = OllamaLLM(\n",
    "    model=\"granite3.3:8b\",\n",
    "    num_ctx=65536, # 64K context window\n",
    ")\n",
    "model = model.bind(raw=True) # Client side controls prompt\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building the Vector Database\n",
    "\n",
    "Now we will input the Model name and corresponding github address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the document\n",
    "\n",
    "Here we you can use Mistral-7B for testin, \"mistralai/Mistral-7B-Instruct-v0.2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "model:  mistralai/Mistral-7B-Instruct-v0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Metadata saved to model_metadata.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "model_name = input(\"model: \").strip()\n",
    "url = f\"https://huggingface.co/api/models/{model_name}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(\"Status code:\", response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    # Convert to pretty JSON string\n",
    "    metadata_text = json.dumps(data, indent=2)\n",
    "    \n",
    "    # Save to a text file\n",
    "    with open(\"model_metadata.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(metadata_text)\n",
    "    \n",
    "    print(\"Metadata saved to model_metadata.txt\")\n",
    "else:\n",
    "    print(\"Error fetching model info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the document into chunks\n",
    "\n",
    "Split the document into text segments that can fit into the model's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3649 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 text document chunks created\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"model_metadata.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=embeddings_tokenizer,\n",
    "    chunk_size=embeddings_tokenizer.max_len_single_sentence,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "doc_id = 0\n",
    "for text in texts:\n",
    "    text.metadata[\"doc_id\"] = (doc_id:=doc_id+1)\n",
    "print(f\"{len(texts)} text document chunks created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Populate the vector database\n",
    "\n",
    "NOTE: Population of the vector database may take over a minute depending on your embedding model and service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 documents added to the vector database\n"
     ]
    }
   ],
   "source": [
    "ids = vector_db.add_documents(texts)\n",
    "print(f\"{len(ids)} documents added to the vector database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying and Return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and Retrun\n",
    "\n",
    "Search the database for similar documents by proximity of the embedded vector in vector space and return the output YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 documents returned\n",
      "page_content='{\n",
      "  \"_id\": \"65770c3426ef61bbf101d4da\",\n",
      "  \"id\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
      "  \"private\": false,\n",
      "  \"pipeline_tag\": \"text-generation\",\n",
      "  \"library_name\": \"transformers\",\n",
      "  \"tags\": [\n",
      "    \"transformers\",\n",
      "    \"pytorch\",\n",
      "    \"safetensors\",\n",
      "    \"mistral\",\n",
      "    \"text-generation\",\n",
      "    \"finetuned\",\n",
      "    \"mistral-common\",\n",
      "    \"conversational\",\n",
      "    \"arxiv:2310.06825\",\n",
      "    \"license:apache-2.0\",\n",
      "    \"autotrain_compatible\",\n",
      "    \"text-generation-inference\",\n",
      "    \"region:us\"\n",
      "  ],\n",
      "  \"downloads\": 1681429,\n",
      "  \"likes\": 2884,\n",
      "  \"modelId\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
      "  \"author\": \"mistralai\",\n",
      "  \"sha\": \"63a8b081895390a26e140280378bc85ec8bce07a\",\n",
      "  \"lastModified\": \"2025-07-24T16:57:21.000Z\",\n",
      "  \"gated\": \"auto\",\n",
      "  \"disabled\": false,\n",
      "  \"widgetData\": [\n",
      "    {\n",
      "      \"messages\": [\n",
      "        {\n",
      "          \"role\": \"user\",\n",
      "          \"content\": \"What is your favorite condiment?\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"model-index\": null,\n",
      "  \"config\": {\n",
      "    \"architectures\": [\n",
      "      \"MistralForCausalLM\"\n",
      "    ],\n",
      "    \"model_type\": \"mistral\",\n",
      "    \"tokenizer_config\": {\n",
      "      \"bos_token\": \"<s>\",\n",
      "      \"chat_template\": \"{%- if messages[0]['role'] == 'system' %}\\n    {%- set system_message = messages[0]['content'] %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n\\n{{- bos_token }}\\n{%- for message in loop_messages %}\\n    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}\\n        {{- raise_exception('After the optional system message, conversation roles must alternate user/assistant/user/assistant/...') }}\\n    {%- endif %}\\n    {%- if message['role'] == 'user' %}\\n        {%- if loop.first and system_message is defined %}\\n            {{- ' [INST] ' + system_message + '\\\\n\\\\n' + message['content'] + ' [/INST]' }}\\n        {%- else %}\\n            {{- ' [INST] ' + message['content'] + ' [/INST]' }}\\n        {%- endif %}\\n    {%- elif message['role'] == 'assistant' %}\\n        {{- ' ' + message['content'] + eos_token}}\\n    {%- else %}\\n        {{- raise_exception('Only user and assistant roles are supported, with the exception of an initial optional system message!') }}\\n    {%- endif %}\\n{%- endfor %}\\n\",\n",
      "      \"eos_token\": \"</s>\",\n",
      "      \"pad_token\": null,\n",
      "      \"unk_token\": \"<unk>\",\n",
      "      \"use_default_system_prompt\": false\n",
      "    }\n",
      "  },\n",
      "  \"cardData\": {\n",
      "    \"library_name\": \"transformers\",\n",
      "    \"license\": \"apache-2.0\",\n",
      "    \"tags\": [\n",
      "      \"finetuned\",\n",
      "      \"mistral-common\"\n",
      "    ],\n",
      "    \"new_version\": \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
      "    \"inference\": false,\n",
      "    \"widget\": [\n",
      "      {\n",
      "        \"messages\": [\n",
      "          {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"What is your favorite condiment?\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"extra_gated_description\": \"If you want to learn more about how we process your personal data, please read our <a href=\\\"https://mistral.ai/terms/\\\">Privacy Policy</a>.\"\n",
      "  },\n",
      "  \"transformersInfo\": {\n",
      "    \"auto_model\": \"AutoModelForCausalLM\",\n",
      "    \"pipeline_tag\": \"text-generation\",\n",
      "    \"processor\": \"AutoTokenizer\"\n",
      "  },\n",
      "  \"siblings\": [\n",
      "    {\n",
      "      \"rfilename\": \".gitattributes\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"README.md\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"config.json\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"generation_config.json\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"model-00001-of-00003.safetensors\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"model-00002-of-00003.safetensors\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"model-00003-of-00003.safetensors\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"model.safetensors.index.json\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"pytorch_model-00001-of-00003.bin\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"pytorch_model-00002-of-00003.bin\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"pytorch_model-00003-of-00003.bin\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"pytorch_model.bin.index.json\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"special_tokens_map.json\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"tokenizer.json\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"tokenizer.model\"\n",
      "    },\n",
      "    {\n",
      "      \"rfilename\": \"tokenizer_config.json\"\n",
      "    }\n",
      "  ],\n",
      "  \"spaces\": [\n",
      "    \"mteb/leaderboard\",\n",
      "    \"KingNish/OpenGPT-4o\",\n",
      "    \"KingNish/JARVIS\",\n",
      "    \"featherless-ai/try-this-model\",\n",
      "    \"allenai/WildBench\",\n",
      "    \"eduagarcia/open_pt_llm_leaderboard\",\n",
      "    \"JournalistsonHF/ai-scraper\",\n",
      "    \"chansung/vid2persona\",\n",
      "    \"allenai/ZebraLogic\",\n",
      "    \"shi-labs/CuMo-7b-zero\",\n",
      "    \"awacke1/GPT-4o-omni-text-audio-image-video\",\n",
      "    \"speakleash/open_pl_llm_leaderboard\",\n",
      "    \"chansung/paper_qa\",\n",
      "    \"MuntasirHossain/RAG-PDF-Chatbot\",\n",
      "    \"barunsaha/slide-deck-ai\",\n",
      "    \"logikon/open_cot_leaderboard\",\n",
      "    \"Ateeqq/Mistral-7B-Instruct-v0.2-Chatbot\",\n",
      "    \"flowers-team/StickToYourRoleLeaderboard\",\n",
      "    \"KBaba7/Quant\",\n",
      "    \"Vision-CAIR/MiniGPT4-video\",\n",
      "    \"mteb/leaderboard_legacy\",\n",
      "    \"Sarath0x8f/Document-QA-bot\",\n",
      "    \"Nymbo/Serverless-TextGen-Hub\",\n",
      "    \"NiansuhAI/HFLLMs\",\n",
      "    \"contextcite/context-cite\",\n",
      "    \"KingNish/Voice-Chat-AI\",\n",
      "    \"fffiloni/miniGPT4-Video-Zero\",\n",
      "    \"AiActivity/AI-Assistant\",\n",
      "    \"Hansimov/hf-llm-api\",\n",
      "    \"awacke1/AI-MovieMaker-Comedy\",\n",
      "    \"Skier8402/mistral-super-fast\",\n",
      "    \"Tuana/hackernews-summaries\",\n",
      "    \"awacke1/Arxiv-Paper-Search-And-QA-RAG-Pattern\",\n",
      "    \"chansung/gradio_together_tgi\",\n",
      "    \"gsarti/pecore\",\n",
      "    \"radinhas/hf-llm-api\",\n",
      "    \"SustainabilityLabIITGN/VayuBuddy\",\n",
      "    \"prometheus-eval/BiGGen-Bench-Leaderboard\",\n",
      "    \"harshitv804/MedChat\",\n",
      "    \"NiansuhAI/Main\",\n",
      "    \"Mr-Vicky-01/chat-with-PDF\",\n",
      "    \"harshitv804/LawGPT\",\n",
      "    \"Justinrune/LLaMA-Factory\",\n",
      "    \"Visal9252/AI_Content_Generator\",\n",
      "    \"Agents-MCP-Hackathon/Huggingface-Space-Commander\",\n",
      "    \"TheBlueberry-AI/Mistral-7b-v0.2\",\n",
      "    \"ROHAN181/pdf-chatbot\",\n",
      "    \"cot-leaderboard/open-cot-dashboard\",\n",
      "    \"MMPano/MMPano\",\n",
      "    \"kartik91/Image-To-Story\",\n",
      "    \"hitmanblade/PowerPoint-AI\",\n",
      "    \"bhaskartripathi/LLM_Quantization\",\n",
      "    \"AFischer1985/AI-RAG-Interface-to-Hub\",\n",
      "    \"asigalov61/Karaoke-MIDI-Search\",\n",
      "    \"kenken999/fastapi_django_main_live\",\n",
      "    \"sepioo/facebook-translation\",\n",
      "    \"devuxious/PowerPoint-AI\",\n",
      "    \"MarkoVidrih/Chat-With-PDF-document\",\n",
      "    \"suriya7/Chatbot-PDF\",\n",
      "    \"ruslanmv/convert_to_gguf\",\n",
      "    \"samim2024/PDF-RAG\",\n",
      "    \"Thun09/leaderboard_demo\",\n",
      "    \"Jaward/optimus\",\n",
      "    \"kaleidoskop-hug/StreamlitChat_Test\",\n",
      "    \"waloneai/PowerPoint-AI-basic\",\n",
      "    \"WildEval/ZebraLogic\",\n",
      "    \"FallnAI/Quantize-HF-Models\",\n",
      "    \"cellerson/AgentCourseFinalProject\",\n",
      "    \"Paul-Joshi/website-summarizers-RAG\",\n",
      "    \"ruslanmv/hf-llm-api\",\n",
      "    \"awacke1/Multimodal-Science-and-Music-Lab\",\n",
      "    \"I-AdityaGoyal/NoteBot\",\n",
      "    \"awacke1/RescuerOfStolenBikes\",\n",
      "    \"dnzblgn/RAG_PDF_langchain\",\n",
      "    \"CyberTud/legalchat\",\n",
      "    \"officialhimanshu595/llama-factory\",\n",
      "    \"awacke1/ScienceBrain.AI\",\n",
      "    \"Sagar23p/mistralAI_chatBoat\",\n",
      "    \"Omdena-MentalHealth-team-consolidated/MindfulMedia_Mentor\",\n",
      "    \"Qazi-Mudassar-Ilyas/RAGWithMSExcel\",\n",
      "    \"dar-tau/selfie\",\n",
      "    \"Pavan178/pdf-chatbot\",\n",
      "    \"awacke1/ChatStreamlitMultiplayer\",\n",
      "    \"awacke1/AIKnowledgeTreeBuilder\",\n",
      "    \"Shashikiran42/Banking_Regulations_Compliance_ChatBOT\",\n",
      "    \"samihalawa/AutoInterpreter\",\n",
      "    \"totolook/Quant\",\n",
      "    \"phucbienvan/AppChat\",\n",
      "    \"helenai/openvino_transformers_streaming\",\n",
      "    \"Annorita/tokenizer_comparison\",\n",
      "    \"wop/BibleLearner_AI\",\n",
      "    \"bardsai/performance-llm-board\",\n",
      "    \"LAWGPT/attorneygpt\",\n",
      "    \"awacke1/The_Music_Of_New_Orleans_MoE\",\n",
      "    \"santuchal/pdf_chat_bot\",\n",
      "    \"itachi-ai/Chat-Bot\",\n",
      "    \"randeom/gpt-prompt-generator\",\n",
      "    \"mehdirab/ResumeParser\",\n",
      "    \"CIVICS-dataset/CIVICS-responses\",\n",
      "    \"mou3az/MCQA-Quiz\"\n",
      "  ],\n",
      "  \"createdAt\": \"2023-12-11T13:18:44.000Z\",\n",
      "  \"safetensors\": {\n",
      "    \"parameters\": {\n",
      "      \"BF16\": 7241732096\n",
      "    },\n",
      "    \"total\": 7241732096\n",
      "  },\n",
      "  \"inference\": \"warm\",\n",
      "  \"usedStorage\": 43979503542\n",
      "}' metadata={'doc_id': 1, 'pk': 459708437463040000, 'source': 'model_metadata.txt'}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"You are a model metadata analyzer and YAML generator.\n",
    "\n",
    "Your task is to fill in the `{{ }}` sections in the YAML template below based only on the provided model documentation.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. If a component is clearly mentioned in the documentation (e.g. model card, training code, datasets), include that component in the `components` section. If it is not mentioned, omit it entirely.\n",
    "2. For each component:\n",
    "   - If a license is found, include its name in `license`.\n",
    "   - If a license path is found, add it in `license_path`. If not, leave it blank.\n",
    "   - If a component file path or URL is available, put it in `component_path`. \n",
    "   - If no specific path is found, default to the Hugging Face model root: `https://huggingface.co/{{ model_name }}`\n",
    "3. Do **not** fabricate any information. Only use what is explicitly stated in the provided documentation or metadata.\n",
    "4. Keep the descriptions exactly as written in the template.\n",
    "5. Use consistent YAML syntax and indentation.\n",
    "\n",
    "### Template to fill:\n",
    "\n",
    "framework:\n",
    "  name: \"Model Openness Framework\"\n",
    "  version: \"1.0\"\n",
    "  date: \"2024-12-15\"\n",
    "\n",
    "release:\n",
    "  name: \"{{ model_name }}\"\n",
    "  version: \"{{ version }}\"\n",
    "  date: \"{{ release_date }}\"\n",
    "  license:\n",
    "    distribution:\n",
    "      name: \"{{ distribution_license }}\"\n",
    "      path: \"{{ distribution_license_path }}\"\n",
    "    code:\n",
    "      name: \"{{ code_license }}\"\n",
    "      path: \"{{ code_license_path }}\"\n",
    "    data:\n",
    "      name: \"{{ data_license }}\"\n",
    "      path: \"{{ data_license_path }}\"\n",
    "    document:\n",
    "      name: \"{{ documentation_license }}\"\n",
    "      path: \"{{ documentation_license_path }}\"\n",
    "  type: \"{{ release_type }}\"\n",
    "  architecture: \"{{ architecture }}\"\n",
    "  origin: \"{{ origin }}\"\n",
    "  producer: \"{{ producer }}\"\n",
    "  contact: \"{{ contact_url }}\"\n",
    "  components:\n",
    "    - name: \"Model architecture\"\n",
    "      description: \"Well commented code for the model's architecture\"\n",
    "      license: unlicensed\n",
    "      component_path: \"{{ model_code_path }}\"\n",
    "\n",
    "    - name: \"Training code\"\n",
    "      description: \"Code used for training the model\"\n",
    "      license: \"{{ training_license }}\"\n",
    "      license_path: \"{{ training_license_path }}\"\n",
    "      component_path: \"{{ training_code_path }}\"\n",
    "\n",
    "    - name: \"Inference code\"\n",
    "      description: \"Code used for running the model to make predictions\"\n",
    "      license: \"{{ inference_license }}\"\n",
    "      license_path: \"{{ inference_license_path }}\"\n",
    "      component_path: \"{{ inference_code_path }}\"\n",
    "\n",
    "    - name: \"Datasets\"\n",
    "      description: \"Training, validation and testing datasets used for the model\"\n",
    "      license: \"{{ dataset_license }}\"\n",
    "      license_path: \"{{ dataset_license_path }}\"\n",
    "      component_path: \"{{ dataset_path }}\"\n",
    "\n",
    "    - name: \"Model card\"\n",
    "      description: \"Model details including performance metrics, intended use, and limitations\"\n",
    "      license: \"{{ model_card_license }}\"\n",
    "      license_path: \"{{ model_card_license_path }}\"\n",
    "      component_path: \"{{ model_card_path }}\"\n",
    "\n",
    "    # Include additional components (e.g., Evaluation code, Data card, Research paper, etc.) only if they are mentioned\n",
    "\n",
    "\"\"\"\n",
    "docs = vector_db.similarity_search(query)\n",
    "print(f\"{len(docs)} documents returned\")\n",
    "for doc in docs:\n",
    "    print(doc)\n",
    "    print(\"=\" * 80)  # Separator for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import escape_f_string\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Create a Granite prompt for question-answering with the retrieved context\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    conversation=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{input}\",\n",
    "    }],\n",
    "    documents=[{\n",
    "        \"doc_id\": \"0\",\n",
    "        \"text\": \"{context}\",\n",
    "    }],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False,\n",
    ")\n",
    "# The Granite prompt can contain JSON strings, so we must escape them\n",
    "prompt_template = PromptTemplate.from_template(template=escape_f_string(prompt, \"input\", \"context\"))\n",
    "\n",
    "# Create a Granite document prompt template to wrap each retrieved document\n",
    "document_prompt_template = PromptTemplate.from_template(template=\"\"\"\\\n",
    "<|end_of_text|>\n",
    "<|start_of_role|>document {{\"document_id\": \"{doc_id}\"}}<|end_of_role|>\n",
    "{page_content}\"\"\")\n",
    "document_separator=\"\"\n",
    "\n",
    "# Assemble the retrieval-augmented generation chain\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=model,\n",
    "    prompt=prompt_template,\n",
    "    document_prompt=document_prompt_template,\n",
    "    document_separator=document_separator,\n",
    ")\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=vector_db.as_retriever(),\n",
    "    combine_docs_chain=combine_docs_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "framework:\n",
      "  name: 'Model Openness Framework'\n",
      "  version: '1.0'\n",
      "  date: '2024-12-15'\n",
      "release:\n",
      "  name: ''\n",
      "  version: ''\n",
      "  date: ''\n",
      "  license:\n",
      "    distribution:\n",
      "      name: 'Apache 2.0'\n",
      "      path: 'license:apache-2.0'\n",
      "    code:\n",
      "      name: ''\n",
      "      path: ''\n",
      "    data:\n",
      "      name: ''\n",
      "      path: ''\n",
      "    document:\n",
      "      name: ''\n",
      "      path: ''\n",
      "  type: ''\n",
      "  architecture: 'MistralForCausalLM'\n",
      "  origin: 'mistralai'\n",
      "  producer: 'Hugging Face'\n",
      "  contact: ''\n",
      "components:\n",
      "  - name: 'Model architecture'\n",
      "    description: \"Well commented code for the model's architecture\"\n",
      "    license: unlicensed\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Data preprocessing code'\n",
      "    description: 'Code for data cleansing, normalization, and augmentation'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Training code'\n",
      "    description: 'Code used for training the model'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Inference code'\n",
      "    description: 'Code used for running the model to make predictions'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Evaluation code'\n",
      "    description: 'Code used for evaluating the model'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Supporting libraries and tools'\n",
      "    description: \"Libraries and tools used in the model's development, includes transformers, pytorch\"\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Model parameters (Final)'\n",
      "    description: 'Trained model parameters, weights and biases, located in model.safetensors'\n",
      "    license: ''\n",
      "    license_path: 'model-00001-of-00003.safetensors, model-00002-of-00003.safetensors, model-00003-of-00003.safetensors'\n",
      "    component_path: 'model.safetensors'\n",
      "\n",
      "  - name: 'Model parameters (Intermediate)'\n",
      "    description: 'Trained model parameters, weights and biases'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: Datasets\n",
      "    description: 'Training, validation and testing datasets used for the model'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Evaluation data'\n",
      "    description: 'Data used for evaluating the model'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Model metadata'\n",
      "    description: 'Any model metadata including training configuration and optimizer states'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Sample model outputs'\n",
      "    description: 'Examples of outputs generated by the model'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Model card'\n",
      "    description: 'Model details including performance metrics, intended use, and limitations'\n",
      "    license: ''\n",
      "    license_path: \"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\"\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Data card'\n",
      "    description: 'Documentation for datasets including source, characteristics, and preprocessing details'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Technical report'\n",
      "    description: 'Technical report detailing capabilities and usage instructions for the model'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Research paper'\n",
      "    description: 'Research paper detailing the development and capabilities of the model'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n",
      "\n",
      "  - name: 'Evaluation results'\n",
      "    description: 'The results from evaluating the model'\n",
      "    license: ''\n",
      "    license_path: ''\n",
      "    component_path: ''\n"
     ]
    }
   ],
   "source": [
    "output = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "print(output['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
